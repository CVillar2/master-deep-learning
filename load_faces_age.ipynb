{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice 1-CNNs (Exercise 2)\n",
    "\n",
    "##### Ovidio Manteiga Moar\n",
    "##### Carlos Villar MartÃ­nez\n",
    "\n",
    "In this first practise weare going to develop a deel learning model using the keras library, we have been given a dataset with 100000 pictures of faces and their corresponding labels. The main goal is creating a model that is capable of determining the gender of person in each photo and the age. In this part we are going to focus on the age prediction part, something important is that we can't train a new model, we must use the model we trained in the previous part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43060,
     "status": "ok",
     "timestamp": 1634385011700,
     "user": {
      "displayName": "Brais CB",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09113625274943472862"
     },
     "user_tz": -120
    },
    "id": "oZSAcVZq5AC9",
    "outputId": "d88c0280-8244-4adb-f4d9-a758d9e2ab60"
   },
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "from os import listdir\n",
    "import os.path\n",
    "\n",
    "PATH = \"C:/Users/corre/OneDrive/Escritorio/Segundo cuatri/DL/Practica 1/datasets/faces/faces_dataset_train/\"\n",
    "PATH_TEST = \"C:/Users/corre/OneDrive/Escritorio/Segundo cuatri/DL/Practica 1/datasets/faces/faces_dataset_test/\"\n",
    "\n",
    "assert os.path.exists(PATH), 'Verify the above commands'\n",
    "assert os.path.exists(PATH_TEST), 'Verify the above commands'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NjzTnkrzNGs"
   },
   "source": [
    "### Metadata access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1634385015531,
     "user": {
      "displayName": "Brais CB",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09113625274943472862"
     },
     "user_tz": -120
    },
    "id": "SciKNCwQzLoy",
    "outputId": "9d46ed8a-cdbc-4c67-8a8c-e5b5b9f430da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i07/nm0322407_rm852269056_1955-3-29_2005.jpg ----> {'age': 50, 'gender': 'M'}\n"
     ]
    }
   ],
   "source": [
    "with open(PATH + 'metadata.json') as fIn:\n",
    "    metadata = json.loads(fIn.read())\n",
    "with open(PATH_TEST + 'metadata.json') as fIn:\n",
    "    metadata_test = json.loads(fIn.read())\n",
    "\n",
    "metadata_example_key = next(iter(metadata.keys()))\n",
    "metadata_example_value = metadata[metadata_example_key]\n",
    "\n",
    "print(metadata_example_key, end=' ----> ')\n",
    "print(metadata_example_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7m5BGd5BboRf"
   },
   "source": [
    "### Image reading\n",
    "\n",
    "Again we import the needed data and create the trainning set and the test set (which again i going to be used s a validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 11855,
     "status": "ok",
     "timestamp": 1634385034194,
     "user": {
      "displayName": "Brais CB",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09113625274943472862"
     },
     "user_tz": -120
    },
    "id": "C11_Qk_RWYoz",
    "outputId": "5b47fc86-f5c9-4f00-f1cb-ab4f268dddd8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n"
     ]
    }
   ],
   "source": [
    "# Size at which images will be processed\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "\n",
    "def decode_img(img):\n",
    "    '''Transforms a string that represents the path of an image into a matrix\n",
    "    (img_height, img_width, 3) of uint8 representing the pixel values\n",
    "    '''\n",
    "    # Convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    # Resize the image to the desired size.\n",
    "    return tf.cast(tf.image.resize(img, [img_height, img_width]),tf.uint8)\n",
    "\n",
    "def process_path(file_path):\n",
    "    '''Transforms strings of the form 'path|age|gender' to tuples (image, label)\n",
    "    '''\n",
    "    parts = tf.strings.split(file_path, '|')\n",
    "    age = parts[1]\n",
    "    age = tf.strings.to_number(age, out_type=tf.dtypes.int32)\n",
    "    gender = parts[2]\n",
    "    # Load the raw data from the file as a string\n",
    "    img = tf.io.read_file(parts[0])\n",
    "    img = decode_img(img)\n",
    "    return img, age\n",
    "\n",
    "\n",
    "def format_metadata(m, path):\n",
    "    '''Transforms the metadata dictionary m into a list of strings of the form 'path to the image|age|gender'.\n",
    "    '''\n",
    "    return list(map(lambda x: '{0}{1}|{2}|{3}'.format(path,x,m[x]['age'],m[x]['gender']),m.keys()))\n",
    "\n",
    "\n",
    "# We build a dataset of text strings from the metadata\n",
    "train_metadata = format_metadata(metadata, PATH)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train_metadata)\n",
    "print(train_ds.take(1))\n",
    "\n",
    "# Mapping to an image dataset with tags\n",
    "train_ds = train_ds.shuffle(len(train_ds)).map(process_path)\n",
    "\n",
    "# Same process for test\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(format_metadata(metadata_test, PATH_TEST))\n",
    "test_ds = test_ds.map(process_path)\n",
    "\n",
    "# Checking\n",
    "#for image, label in train_ds.take(5):\n",
    "#    print(\"Image shape: \", image.numpy().shape)\n",
    "#    print(\"Label: \", label.numpy())\n",
    "#    pyplot.imshow(image.numpy())\n",
    "#    pyplot.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1634385053497,
     "user": {
      "displayName": "Brais CB",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09113625274943472862"
     },
     "user_tz": -120
    },
    "id": "hYx17xd8jDp-",
    "outputId": "960a5992-2ac4-4cc4-9ff9-58ab89cbec7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/corre/OneDrive/Escritorio/Segundo cuatri/DL/Practica 1/datasets/faces/faces_dataset_train/i07/nm0322407_rm852269056_1955-3-29_2005.jpg|50|M\n"
     ]
    }
   ],
   "source": [
    "ds_train_transform = train_ds\n",
    "ds_test_transform = test_ds\n",
    "print(train_metadata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EtsmgEMAil8H"
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: rescaling input to [-1, 1]\n",
    "ds_train_transform = ds_train_transform.map(lambda image, label: (tf.cast(image, tf.float32)/127.5 - 1., label))\n",
    "ds_test_transform = ds_test_transform.map(lambda image, label: (tf.cast(image, tf.float32)/127.5 - 1., label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "L09prZNx7uWn"
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: rescaled output to [0, 1]\n",
    "labels = [int(x.split('|')[1]) for x in train_metadata]\n",
    "max_age = tf.convert_to_tensor(np.max(labels), tf.float32)\n",
    "ds_train_transform = ds_train_transform.map(lambda image, label: (image, tf.cast(label, tf.float32)/max_age))\n",
    "ds_test_transform = ds_test_transform.map(lambda image, label: (image, tf.cast(label, tf.float32)/max_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1634336490127,
     "user": {
      "displayName": "Brais CB",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09113625274943472862"
     },
     "user_tz": -120
    },
    "id": "lgiNRV9MhIPQ",
    "outputId": "5ff366d2-afc0-4be9-f22d-29833dc8cdd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[1.76150383 0.08628557 0.01546083 0.01225852 0.01755069 0.03502511\n",
      " 0.06879879 0.16056922 0.52553153 7.31701591], shape=(10,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: sample age weights\n",
    "step = 10\n",
    "labels = [int(x.split('|')[1]) for x in train_metadata]\n",
    "freqs, bins = np.histogram(labels, bins=list(range(0,100,step)) + [200])\n",
    "i_freqs = 1. / freqs\n",
    "sample_weights = tf.convert_to_tensor(len(i_freqs) * i_freqs / i_freqs.sum())\n",
    "print(sample_weights)\n",
    "ds_train_transform = ds_train_transform.map(lambda image, label: (image, label, sample_weights[tf.minimum(tf.cast(label, tf.int32) // step, len(i_freqs) - 1)]))\n",
    "ds_test_transform = ds_test_transform.map(lambda image, label: (image, label, sample_weights[tf.minimum(tf.cast(label, tf.int32) // step, len(i_freqs) - 1)]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size\n",
    "Again we need to choose a batch size that adaps to our trainning set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1634385057992,
     "user": {
      "displayName": "Brais CB",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09113625274943472862"
     },
     "user_tz": -120
    },
    "id": "x0vHwUzTAjJ9"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "ds_train_batch = ds_train_transform.batch(batch_size)\n",
    "ds_test_batch = ds_test_transform.batch(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the old model\n",
    "\n",
    "Here we load the trained model of the previous practise. To do it we have to import from keras 'load_model'. After loading the old model we can see it's summary which should be the same as before and, to make sure that it won't train we can define 'trainable = False' in some cell after loading it. Now, for creating the new model we delete the last layer of the old model and we add a new one and three dense layer more, as it is a regression problem two of the dense layers are using 'activation = 'relu' and the last layer is using 'activation = 'linear'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the pretrained model \n",
    "old_model = load_model(\"genre_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 1, 128)         65664     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168,289\n",
      "Trainable params: 168,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "old_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make it non trainable\n",
    "old_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the new model\n",
    "\n",
    "new_model = Sequential()\n",
    "for layer in old_model.layers[:-1]:\n",
    "    new_model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It has a single output neuron and a sigmoid activation\n",
    "\n",
    "new_model.add(Dense(256, activation='relu'))\n",
    "new_model.add(Dense(128, activation='relu'))\n",
    "new_model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 1, 128)         65664     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 234,209\n",
      "Trainable params: 66,049\n",
      "Non-trainable params: 168,160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile\n",
    "Again we have to compile the model, we decided to use here the adam optimizer as it is one of the most used in regresion problems and, for the metrics, we are using mean absolute error because we are asked to use it in the statement of the practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(optimizer=\"adam\",\n",
    "                  loss=\"mse\",\n",
    "                  metrics=[\"mean_absolute_error\"],\n",
    "                  weighted_metrics=[])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "As it's mentioned before all the part of the model that belongs to the old model can't be trained. Again we are using the the test set as validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "496/496 [==============================] - 29s 56ms/step - loss: 0.0421 - mean_absolute_error: 0.1163 - val_loss: 0.1406 - val_mean_absolute_error: 0.2355\n",
      "Epoch 2/15\n",
      "496/496 [==============================] - 29s 58ms/step - loss: 0.0333 - mean_absolute_error: 0.1081 - val_loss: 0.1343 - val_mean_absolute_error: 0.2301\n",
      "Epoch 3/15\n",
      "496/496 [==============================] - 31s 62ms/step - loss: 0.0327 - mean_absolute_error: 0.1069 - val_loss: 0.1358 - val_mean_absolute_error: 0.2338\n",
      "Epoch 4/15\n",
      "496/496 [==============================] - 33s 67ms/step - loss: 0.0325 - mean_absolute_error: 0.1067 - val_loss: 0.1380 - val_mean_absolute_error: 0.2357\n",
      "Epoch 5/15\n",
      "496/496 [==============================] - 29s 59ms/step - loss: 0.0321 - mean_absolute_error: 0.1060 - val_loss: 0.1425 - val_mean_absolute_error: 0.2375\n",
      "Epoch 6/15\n",
      "496/496 [==============================] - 30s 61ms/step - loss: 0.0321 - mean_absolute_error: 0.1059 - val_loss: 0.1377 - val_mean_absolute_error: 0.2341\n",
      "Epoch 7/15\n",
      "496/496 [==============================] - 30s 61ms/step - loss: 0.0319 - mean_absolute_error: 0.1056 - val_loss: 0.1374 - val_mean_absolute_error: 0.2340\n",
      "Epoch 8/15\n",
      "496/496 [==============================] - 34s 68ms/step - loss: 0.0319 - mean_absolute_error: 0.1057 - val_loss: 0.1354 - val_mean_absolute_error: 0.2338\n",
      "Epoch 9/15\n",
      "496/496 [==============================] - 34s 67ms/step - loss: 0.0319 - mean_absolute_error: 0.1055 - val_loss: 0.1381 - val_mean_absolute_error: 0.2349\n",
      "Epoch 10/15\n",
      "496/496 [==============================] - 35s 69ms/step - loss: 0.0318 - mean_absolute_error: 0.1053 - val_loss: 0.1367 - val_mean_absolute_error: 0.2342\n",
      "Epoch 11/15\n",
      "496/496 [==============================] - 33s 67ms/step - loss: 0.0318 - mean_absolute_error: 0.1054 - val_loss: 0.1370 - val_mean_absolute_error: 0.2352\n",
      "Epoch 12/15\n",
      "496/496 [==============================] - 34s 69ms/step - loss: 0.0318 - mean_absolute_error: 0.1054 - val_loss: 0.1383 - val_mean_absolute_error: 0.2355\n",
      "Epoch 13/15\n",
      "496/496 [==============================] - 33s 67ms/step - loss: 0.0318 - mean_absolute_error: 0.1054 - val_loss: 0.1339 - val_mean_absolute_error: 0.2320\n",
      "Epoch 14/15\n",
      "496/496 [==============================] - 35s 70ms/step - loss: 0.0317 - mean_absolute_error: 0.1052 - val_loss: 0.1344 - val_mean_absolute_error: 0.2325\n",
      "Epoch 15/15\n",
      "496/496 [==============================] - 34s 68ms/step - loss: 0.0318 - mean_absolute_error: 0.1052 - val_loss: 0.1407 - val_mean_absolute_error: 0.2373\n"
     ]
    }
   ],
   "source": [
    "history = new_model.fit(ds_train_batch,\n",
    "                        epochs=15,\n",
    "                        validation_data=ds_test_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean absolute error\n",
    "\n",
    "Let's see now the value of the mean absolute error in years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error of trainning in years: 10.52 years\n",
      "Mean absolute error of validation in years: 23.73 years\n"
     ]
    }
   ],
   "source": [
    "training_error = history.history[\"mean_absolute_error\"]\n",
    "validation_error = history.history[\"val_mean_absolute_error\"]\n",
    "\n",
    "training_error = training_error[-1]*100\n",
    "validation_error = validation_error[-1]*100\n",
    "\n",
    "print(\"Mean absolute error of trainning in years:\", f\"{training_error:.2f}\", \"years\")\n",
    "print(\"Mean absolute error of validation in years:\", f\"{validation_error:.2f}\", \"years\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and conclusions\n",
    "The results obtained for this part are not really good, when we correct the error that there was in the original code the validation mean absolute error went from 0.10 to 0.23 which is quite disapointing. We would like to try more models to improve this result but we had no time."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Proyecto_naive_edad.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
