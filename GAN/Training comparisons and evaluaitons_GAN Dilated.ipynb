{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Comparisons and Evaluations\n",
    "\n",
    "##### Authors:\n",
    "1. Ovidio Manteiga Moar\n",
    "1. Carlos Villar Mart√≠nez\n",
    "\n",
    "In this notebook the goal is to train a GAN and udsing dilatation. The notebook is similar to the one with the GAN but with a few changes that will be comented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, utils, metrics, optimizers\n",
    "from Data_pre import prepare_data_generator_GAN\n",
    "\n",
    "from utils import display"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"./Dataset/img_align_celeba\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when choosing the hyperparameters we have to make a change, the IMAGE_SIZE is set to 112 because with the factor 2 of the dilatation if we keep using 64 we will get an error in the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 112\n",
    "CHANNELS = 1\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "NUM_FEATURES = 64\n",
    "Z_DIM = 100\n",
    "\n",
    "EPOCHS = 5\n",
    "STEPS_PER_EPOCH=100\n",
    "\n",
    "LEARNING_RATE = 0.0002\n",
    "CRITIC_STEPS = 3\n",
    "\n",
    "ADAM_BETA_1 = 0.5\n",
    "ADAM_BETA_2 = 0.999\n",
    "\n",
    "GP_WEIGHT = 10.0\n",
    "LOAD_MODEL = False\n",
    "ADAM_BETA_1 = 0.5\n",
    "ADAM_BETA_2 = 0.9\n",
    "\n",
    "#COLOR_MODE \"rgb\" or \"graysacale\"\n",
    "COLOR_MODE = \"grayscale\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the defined function in the Data_pre.py file we do all the needed data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train = prepare_data_generator_GAN(DATA_FOLDER, IMAGE_SIZE, BATCH_SIZE, COLOR_MODE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building tthe WGAN-GP\n",
    "\n",
    "It is here when we apply the dilation to the GAN, in the first Conv2D layer for the critic_input model and in the first Conv2DTraspose layer for the generator_input we use the dilation_rate=2. We can use this if strides=1, adn it is something quite important to take into account. [Conv2D_documentation](https://keras.io/api/layers/convolution_layers/convolution2d/) \n",
    "\n",
    "The rest of the code is the same than for the GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 112, 112, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 112, 112, 64)      1088      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 56, 56, 128)       131200    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 256)       524544    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 512)       2097664   \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 11, 11, 1)         8193      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 121)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,762,689\n",
      "Trainable params: 2,762,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "critic_input = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
    "x = layers.Conv2D(64, kernel_size=4, strides=1, dilation_rate=2, padding=\"same\")(critic_input)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(256, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(512, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(1, kernel_size=4, strides=1, padding=\"valid\")(x)\n",
    "critic_output = layers.Flatten()(x)\n",
    "\n",
    "critic = models.Model(critic_input, critic_output)\n",
    "critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 1, 100)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 7, 7, 512)        819200    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 7, 7, 512)        2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 256)      2097152   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 128)      524288    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 28, 28, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 56, 56, 64)       131072    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 56, 56, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 112, 112, 1)      1025      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,576,577\n",
      "Trainable params: 3,574,657\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_input = layers.Input(shape=(Z_DIM,))\n",
    "x = layers.Reshape((1, 1, Z_DIM))(generator_input)\n",
    "x = layers.Conv2DTranspose(512, kernel_size=4, strides=1, dilation_rate = 2, padding=\"valid\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "generator_output = layers.Conv2DTranspose(CHANNELS, kernel_size=4, strides=2, padding=\"same\", activation=\"tanh\")(x)\n",
    "generator = models.Model(generator_input, generator_output)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANGP(models.Model):\n",
    "    def __init__(self, critic, generator, latent_dim, critic_steps, gp_weight):\n",
    "        super(WGANGP, self).__init__()\n",
    "        self.critic = critic\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.critic_steps = critic_steps\n",
    "        self.gp_weight = gp_weight\n",
    "\n",
    "    def compile(self, c_optimizer, g_optimizer):\n",
    "        super(WGANGP, self).compile()\n",
    "        self.c_optimizer = c_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.c_wass_loss_metric = metrics.Mean(name=\"c_wass_loss\")\n",
    "        self.c_gp_metric = metrics.Mean(name=\"c_gp\")\n",
    "        self.c_loss_metric = metrics.Mean(name=\"c_loss\")\n",
    "        self.g_loss_metric = metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.c_loss_metric, self.c_wass_loss_metric, self.c_gp_metric, self.g_loss_metric]\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            pred = self.critic(interpolated, training=True)\n",
    "\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        for i in range(self.critic_steps):\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_images = self.generator(random_latent_vectors, training=True)\n",
    "                fake_predictions = self.critic(fake_images, training=True)\n",
    "                real_predictions = self.critic(real_images, training=True)\n",
    "\n",
    "                c_wass_loss = tf.reduce_mean(fake_predictions) - tf.reduce_mean(real_predictions)\n",
    "                c_gp = self.gradient_penalty(batch_size, real_images, fake_images)\n",
    "                c_loss = c_wass_loss + c_gp * self.gp_weight\n",
    "\n",
    "            c_gradient = tape.gradient(c_loss, self.critic.trainable_variables)\n",
    "            self.c_optimizer.apply_gradients(zip(c_gradient, self.critic.trainable_variables))\n",
    "\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_latent_vectors, training=True)\n",
    "            fake_predictions = self.critic(fake_images, training=True)\n",
    "            g_loss = -tf.reduce_mean(fake_predictions)\n",
    "\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(gen_gradient, self.generator.trainable_variables))\n",
    "\n",
    "        \"\"\"\n",
    "        self.c_loss_metric.update_state(c_loss)\n",
    "        self.c_wass_loss_metric.update_state(c_wass_loss)\n",
    "        self.c_gp_metric.update_state(c_gp)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "      # Calculate Critic and Generator Accuracy\n",
    "        c_acc = tf.reduce_mean(tf.cast(tf.math.greater(real_predictions, 0), tf.float32)) * 100\n",
    "        g_acc = tf.reduce_mean(tf.cast(tf.math.less(fake_predictions, 0), tf.float32)) * 100\n",
    "\n",
    "        self.c_loss_metric.update_state(c_loss)\n",
    "        self.c_wass_loss_metric.update_state(c_wass_loss)\n",
    "        self.c_gp_metric.update_state(c_gp)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "\n",
    "        #return {m.name: m.result() for m in self.metrics,'c_acc': c_acc,'g_acc': g_acc}    \n",
    "        return {**{m.name: m.result() for m in self.metrics}, 'c_acc': c_acc, 'g_acc': g_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GAN\n",
    "wgangp = WGANGP(critic=critic, generator=generator, latent_dim=Z_DIM, critic_steps=CRITIC_STEPS, gp_weight=GP_WEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    wgangp.load_weights(\"./checkpoint/checkpoint.ckpt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the GAN\n",
    "wgangp.compile(\n",
    "    c_optimizer=optimizers.Adam(learning_rate=LEARNING_RATE, beta_1=ADAM_BETA_1, beta_2=ADAM_BETA_2),\n",
    "    g_optimizer=optimizers.Adam(learning_rate=LEARNING_RATE, beta_1=ADAM_BETA_1, beta_2=ADAM_BETA_2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 112, 112, 1)\n",
      "(112, 112, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create a model save checkpoint\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=\"./checkpoint/checkpoint.ckpt\",\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "\n",
    "real_images = np.array(list(train.unbatch().take(10).as_numpy_iterator()))\n",
    "print(real_images.shape)\n",
    "print(real_images[0].shape)\n",
    "from fid import get_fid\n",
    "\n",
    "class ImageGenerator(callbacks.Callback):\n",
    "    def __init__(self, num_img, latent_dim):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        self.history = { 'fid': [] }\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images = generated_images * 127.5 + 127.5\n",
    "        generated_images = generated_images.numpy()\n",
    "        display(generated_images, save_to=\"./output/generated_img_%03d.png\" % (epoch), cmap=None)\n",
    "        fid = get_fid(real_images, generated_images)\n",
    "        self.history['fid'].append(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.history = {\n",
    "            'c_loss': [],\n",
    "            'g_loss': [],\n",
    "            'c_acc': [],\n",
    "            'g_acc': [],\n",
    "        }\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.history['c_loss'].append(logs['c_loss'])\n",
    "        self.history['g_loss'].append(logs['g_loss'])\n",
    "        self.history['c_acc'].append(logs['c_acc'])\n",
    "        self.history['g_acc'].append(logs['g_acc'])\n",
    "\n",
    "loss_history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "loss_history = LossHistory()\n",
    "\n",
    "wgangp.fit(\n",
    "    train,\n",
    "    #train.take(1),\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    #steps_per_epoch=1,\n",
    "    callbacks=[model_checkpoint_callback, tensorboard_callback, ImageGenerator(num_img=10, latent_dim=Z_DIM), loss_history],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that we have a problem. Instead of having the five epochs and the results we can just see: Epoch 1/5. This is because when we tried to train this model the computer just gave us a blue screen, we tried modifying some hyperparameters we the computer kept giving a blue screen. It was not a problem with the kernel or something like that, simply the computer could not bear with it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_sample = np.random.normal(size=(10, Z_DIM))\n",
    "imgs = wgangp.generator.predict(z_sample)\n",
    "display(imgs, cmap=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses_and_accuracy(loss_history):\n",
    "    epochs = len(loss_history.history['c_loss'])\n",
    "    x = range(epochs)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    \n",
    "    axs[0, 0].plot(x, loss_history.history['c_loss'], label=\"Critic Loss\")\n",
    "    axs[0, 0].set(xlabel=\"Epochs\", ylabel=\"Loss\")\n",
    "    axs[0, 0].legend()\n",
    "    \n",
    "    axs[0, 1].plot(x, loss_history.history['g_loss'], label=\"Generator Loss\")\n",
    "    axs[0, 1].set(xlabel=\"Epochs\", ylabel=\"Loss\")\n",
    "    axs[0, 1].legend()\n",
    "    \n",
    "    axs[1, 0].plot(x, loss_history.history['c_acc'], label=\"Critic Accuracy\")\n",
    "    axs[1, 0].set(xlabel=\"Epochs\", ylabel=\"Accuracy\")\n",
    "    axs[1, 0].legend()\n",
    "    \n",
    "    axs[1, 1].plot(x, loss_history.history['g_acc'], label=\"Generator Accuracy\")\n",
    "    axs[1, 1].set(xlabel=\"Epochs\", ylabel=\"Accuracy\")\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_losses_and_accuracy(loss_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
